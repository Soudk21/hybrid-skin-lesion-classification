{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-18T19:41:15.987543Z",
     "iopub.status.busy": "2025-08-18T19:41:15.987185Z",
     "iopub.status.idle": "2025-08-18T19:41:27.110028Z",
     "shell.execute_reply": "2025-08-18T19:41:27.108789Z",
     "shell.execute_reply.started": "2025-08-18T19:41:15.987514Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 19:41:16.830312: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1755546076.859270      98 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1755546076.867654      98 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformers import TFResNetModel, AutoImageProcessor\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T19:41:31.441754Z",
     "iopub.status.busy": "2025-08-18T19:41:31.440059Z",
     "iopub.status.idle": "2025-08-18T19:41:31.447729Z",
     "shell.execute_reply": "2025-08-18T19:41:31.445986Z",
     "shell.execute_reply.started": "2025-08-18T19:41:31.441700Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "handcrafted_features_path = '/kaggle/input/features/features.csv'  # Update with actual input dataset name\n",
    "metadata_path = '/kaggle/input/metadata-csv/HAM10000_metadata.csv'  # Update with actual\n",
    "image_part1_path = '/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_1'\n",
    "image_part2_path = '/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T19:41:34.927702Z",
     "iopub.status.busy": "2025-08-18T19:41:34.927285Z",
     "iopub.status.idle": "2025-08-18T19:41:36.562511Z",
     "shell.execute_reply": "2025-08-18T19:41:36.561549Z",
     "shell.execute_reply.started": "2025-08-18T19:41:34.927673Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "2025-08-18 19:41:35.192800: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFResNetModel: ['resnet.encoder.stages.1.layers.1.layer.1.normalization.num_batches_tracked', 'resnet.encoder.stages.1.layers.2.layer.1.normalization.num_batches_tracked', 'resnet.encoder.stages.3.layers.2.layer.0.normalization.num_batches_tracked', 'resnet.encoder.stages.2.layers.1.layer.2.normalization.num_batches_tracked', 'resnet.encoder.stages.0.layers.0.layer.1.normalization.num_batches_tracked', 'resnet.embedder.embedder.normalization.num_batches_tracked', 'resnet.encoder.stages.1.layers.3.layer.2.normalization.num_batches_tracked', 'resnet.encoder.stages.3.layers.2.layer.2.normalization.num_batches_tracked', 'resnet.encoder.stages.0.layers.0.layer.2.normalization.num_batches_tracked', 'resnet.encoder.stages.1.layers.3.layer.0.normalization.num_batches_tracked', 'resnet.encoder.stages.0.layers.2.layer.0.normalization.num_batches_tracked', 'resnet.encoder.stages.2.layers.3.layer.2.normalization.num_batches_tracked', 'resnet.encoder.stages.1.layers.3.layer.1.normalization.num_batches_tracked', 'resnet.encoder.stages.2.layers.1.layer.1.normalization.num_batches_tracked', 'resnet.encoder.stages.1.layers.0.shortcut.normalization.num_batches_tracked', 'resnet.encoder.stages.2.layers.0.layer.2.normalization.num_batches_tracked', 'resnet.encoder.stages.3.layers.0.shortcut.normalization.num_batches_tracked', 'resnet.encoder.stages.2.layers.5.layer.0.normalization.num_batches_tracked', 'resnet.encoder.stages.2.layers.0.shortcut.normalization.num_batches_tracked', 'resnet.encoder.stages.0.layers.1.layer.1.normalization.num_batches_tracked', 'resnet.encoder.stages.1.layers.0.layer.2.normalization.num_batches_tracked', 'resnet.encoder.stages.2.layers.4.layer.2.normalization.num_batches_tracked', 'resnet.encoder.stages.2.layers.4.layer.1.normalization.num_batches_tracked', 'resnet.encoder.stages.2.layers.4.layer.0.normalization.num_batches_tracked', 'resnet.encoder.stages.1.layers.1.layer.2.normalization.num_batches_tracked', 'classifier.1.bias', 'resnet.encoder.stages.3.layers.2.layer.1.normalization.num_batches_tracked', 'resnet.encoder.stages.3.layers.0.layer.2.normalization.num_batches_tracked', 'resnet.encoder.stages.0.layers.0.shortcut.normalization.num_batches_tracked', 'resnet.encoder.stages.2.layers.3.layer.1.normalization.num_batches_tracked', 'resnet.encoder.stages.2.layers.0.layer.1.normalization.num_batches_tracked', 'resnet.encoder.stages.2.layers.2.layer.2.normalization.num_batches_tracked', 'resnet.encoder.stages.3.layers.1.layer.1.normalization.num_batches_tracked', 'classifier.1.weight', 'resnet.encoder.stages.2.layers.2.layer.1.normalization.num_batches_tracked', 'resnet.encoder.stages.3.layers.0.layer.0.normalization.num_batches_tracked', 'resnet.encoder.stages.3.layers.0.layer.1.normalization.num_batches_tracked', 'resnet.encoder.stages.0.layers.1.layer.2.normalization.num_batches_tracked', 'resnet.encoder.stages.2.layers.5.layer.2.normalization.num_batches_tracked', 'resnet.encoder.stages.3.layers.1.layer.2.normalization.num_batches_tracked', 'resnet.encoder.stages.0.layers.1.layer.0.normalization.num_batches_tracked', 'resnet.encoder.stages.2.layers.0.layer.0.normalization.num_batches_tracked', 'resnet.encoder.stages.0.layers.2.layer.2.normalization.num_batches_tracked', 'resnet.encoder.stages.2.layers.5.layer.1.normalization.num_batches_tracked', 'resnet.encoder.stages.1.layers.1.layer.0.normalization.num_batches_tracked', 'resnet.encoder.stages.2.layers.2.layer.0.normalization.num_batches_tracked', 'resnet.encoder.stages.1.layers.0.layer.0.normalization.num_batches_tracked', 'resnet.encoder.stages.2.layers.1.layer.0.normalization.num_batches_tracked', 'resnet.encoder.stages.1.layers.0.layer.1.normalization.num_batches_tracked', 'resnet.encoder.stages.2.layers.3.layer.0.normalization.num_batches_tracked', 'resnet.encoder.stages.1.layers.2.layer.0.normalization.num_batches_tracked', 'resnet.encoder.stages.0.layers.2.layer.1.normalization.num_batches_tracked', 'resnet.encoder.stages.1.layers.2.layer.2.normalization.num_batches_tracked', 'resnet.encoder.stages.3.layers.1.layer.0.normalization.num_batches_tracked', 'resnet.encoder.stages.0.layers.0.layer.0.normalization.num_batches_tracked']\n",
      "- This IS expected if you are initializing TFResNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFResNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFResNetModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFResNetModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Load ResNet50 from Hugging Face\n",
    "processor = AutoImageProcessor.from_pretrained('microsoft/resnet-50')\n",
    "base_model = TFResNetModel.from_pretrained('microsoft/resnet-50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T19:41:40.994808Z",
     "iopub.status.busy": "2025-08-18T19:41:40.994317Z",
     "iopub.status.idle": "2025-08-18T19:41:41.031545Z",
     "shell.execute_reply": "2025-08-18T19:41:41.030424Z",
     "shell.execute_reply.started": "2025-08-18T19:41:40.994740Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load metadata for labels\n",
    "metadata_df = pd.read_csv(metadata_path)\n",
    "metadata_df['label'] = metadata_df['dx'].apply(lambda x: 1 if x == 'mel' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T19:41:44.890114Z",
     "iopub.status.busy": "2025-08-18T19:41:44.889664Z",
     "iopub.status.idle": "2025-08-18T19:41:44.910242Z",
     "shell.execute_reply": "2025-08-18T19:41:44.908883Z",
     "shell.execute_reply.started": "2025-08-18T19:41:44.890081Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Prepare dataset for fine-tuning (binary classification)\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, val_df = train_test_split(metadata_df, test_size=0.2, stratify=metadata_df['label'], random_state=42)\n",
    "\n",
    "# Create TF datasets for fine-tuning\n",
    "def load_image(file_path, label):\n",
    "    def process_image_fn(file_path):\n",
    "        # Load and decode image\n",
    "        img = tf.io.read_file(file_path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, [224, 224])\n",
    "        img = tf.cast(img, tf.uint8)\n",
    "        \n",
    "        # Convert to numpy for the processor\n",
    "        img_np = img.numpy()\n",
    "        \n",
    "        # Use processor (returns numpy array when return_tensors='np')\n",
    "        processed = processor(images=img_np, return_tensors='np')\n",
    "        return processed['pixel_values'][0].astype('float32')\n",
    "    \n",
    "    # Use tf.py_function to handle the mixed operations\n",
    "    pixel_values = tf.py_function(\n",
    "        process_image_fn,\n",
    "        [file_path],\n",
    "        tf.float32\n",
    "    )\n",
    "    \n",
    "    # ResNet processor outputs to set shape accordingly\n",
    "    pixel_values.set_shape([3, 224, 224])\n",
    "    \n",
    "    return pixel_values, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T19:41:57.525985Z",
     "iopub.status.busy": "2025-08-18T19:41:57.525515Z",
     "iopub.status.idle": "2025-08-18T19:42:01.472557Z",
     "shell.execute_reply": "2025-08-18T19:42:01.471351Z",
     "shell.execute_reply.started": "2025-08-18T19:41:57.525931Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Get full image paths\n",
    "train_df['file_path'] = train_df['image_id'].apply(lambda x: os.path.join(image_part1_path if os.path.exists(os.path.join(image_part1_path, x + '.jpg')) else image_part2_path, x + '.jpg'))\n",
    "val_df['file_path'] = val_df['image_id'].apply(lambda x: os.path.join(image_part1_path if os.path.exists(os.path.join(image_part1_path, x + '.jpg')) else image_part2_path, x + '.jpg'))\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_df['file_path'], train_df['label']))\n",
    "train_dataset = train_dataset.map(load_image, num_parallel_calls=tf.data.AUTOTUNE).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_df['file_path'], val_df['label']))\n",
    "val_dataset = val_dataset.map(load_image, num_parallel_calls=tf.data.AUTOTUNE).batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T19:42:06.522188Z",
     "iopub.status.busy": "2025-08-18T19:42:06.521721Z",
     "iopub.status.idle": "2025-08-18T19:42:09.592170Z",
     "shell.execute_reply": "2025-08-18T19:42:09.591058Z",
     "shell.execute_reply.started": "2025-08-18T19:42:06.522150Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Add classification head for fine-tuning\n",
    "inputs = tf.keras.Input(shape=(3, 224, 224))  # Match processor output shape\n",
    "x = base_model(inputs, training=True).last_hidden_state  # Use base_model directly, not base_model.resnet\n",
    "# For ResNet, last_hidden_state should be pooled\n",
    "x = tf.keras.layers.GlobalAveragePooling2D(data_format='channels_first')(x)  # Specify channels_first\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "fine_tune_model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Compile and fine-tune\n",
    "fine_tune_model.compile(optimizer=tf.keras.optimizers.Adam(1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "fine_tune_model.fit(train_dataset, validation_data=val_dataset, epochs=5)  # Adjust epochs as needed\n",
    "\n",
    "# Use fine-tuned model for extraction\n",
    "model = fine_tune_model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T19:42:13.603020Z",
     "iopub.status.busy": "2025-08-18T19:42:13.602524Z",
     "iopub.status.idle": "2025-08-18T19:42:20.531950Z",
     "shell.execute_reply": "2025-08-18T19:42:20.530880Z",
     "shell.execute_reply.started": "2025-08-18T19:42:13.602983Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "model = fine_tune_model\n",
    "\n",
    "model = tf.keras.models.load_model(\n",
    "    '/kaggle/input/fine-tuned/tensorflow2/default/1/fine_tuned_resnet50.h5',\n",
    "    custom_objects={'TFResNetModel': TFResNetModel}  # Register the custom layer\n",
    ")\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T19:42:25.394676Z",
     "iopub.status.busy": "2025-08-18T19:42:25.394182Z",
     "iopub.status.idle": "2025-08-18T19:42:25.402062Z",
     "shell.execute_reply": "2025-08-18T19:42:25.400882Z",
     "shell.execute_reply.started": "2025-08-18T19:42:25.394636Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Feature Extraction Function (using the fine-tuned model)\n",
    "def extract_features(image_path):\n",
    "    img = Image.open(image_path).resize((224, 224))\n",
    "    img_array = np.array(img)\n",
    "    inputs = processor(img_array, return_tensors='tf')\n",
    "    \n",
    "    # Get features from the layer before the final classification layer\n",
    "    feature_extractor = tf.keras.Model(inputs=model.input, outputs=model.layers[-2].output)\n",
    "    features = feature_extractor(inputs['pixel_values'], training=False)\n",
    "    features = features.numpy().flatten()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T19:42:31.420514Z",
     "iopub.status.busy": "2025-08-18T19:42:31.420028Z",
     "iopub.status.idle": "2025-08-18T20:43:35.700758Z",
     "shell.execute_reply": "2025-08-18T20:43:35.697982Z",
     "shell.execute_reply.started": "2025-08-18T19:42:31.420482Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [29:58<00:00,  2.78it/s]\n",
      "100%|██████████| 5015/5015 [30:22<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw features saved to '/kaggle/working/resnet50_finetuned_raw_features.csv'\n"
     ]
    }
   ],
   "source": [
    "# Extract features for all images\n",
    "feature_vectors = []\n",
    "image_ids = []\n",
    "for dir_path in [image_part1_path, image_part2_path]:\n",
    "    for img_file in tqdm(os.listdir(dir_path)):\n",
    "        if img_file.endswith('.jpg'):\n",
    "            img_path = os.path.join(dir_path, img_file)\n",
    "            features = extract_features(img_path)\n",
    "            feature_vectors.append(features)\n",
    "            image_ids.append(img_file.replace('.jpg', ''))\n",
    "            \n",
    "# Create DataFrame and save raw features\n",
    "features_df = pd.DataFrame(feature_vectors, index=image_ids)\n",
    "features_df.to_csv('/kaggle/working/resnet50_finetuned_raw_features.csv')\n",
    "print(\"Raw features saved to '/kaggle/working/resnet50_finetuned_raw_features.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T20:50:42.728411Z",
     "iopub.status.busy": "2025-08-18T20:50:42.727799Z",
     "iopub.status.idle": "2025-08-18T20:52:41.498966Z",
     "shell.execute_reply": "2025-08-18T20:52:41.497901Z",
     "shell.execute_reply.started": "2025-08-18T20:50:42.728373Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redundant DL features to drop: []\n"
     ]
    }
   ],
   "source": [
    "# Load hand-crafted features for redundancy check\n",
    "handcrafted_df = pd.read_csv(handcrafted_features_path, index_col='image_id')\n",
    "\n",
    "common_ids = list(set(features_df.index) & set(handcrafted_df.index))\n",
    "dl_df = features_df.loc[common_ids]\n",
    "hand_df = handcrafted_df.loc[common_ids]\n",
    "\n",
    "# Convert columns to strings to avoid mixed type issues\n",
    "dl_df.columns = dl_df.columns.astype(str)\n",
    "hand_df.columns = hand_df.columns.astype(str)\n",
    "\n",
    "concat_df = pd.concat([dl_df, hand_df], axis=1)\n",
    "corr_matrix = concat_df.corr().abs()\n",
    "corr_between = corr_matrix.iloc[:len(dl_df.columns), len(dl_df.columns):]\n",
    "\n",
    "to_drop_dl = [dl_col for dl_col in dl_df.columns if (corr_between.loc[dl_col] > 0.7).any()]  # Use loc for row access\n",
    "print(f\"Redundant DL features to drop: {to_drop_dl}\")\n",
    "\n",
    "# Remove from DL\n",
    "dl_reduced = dl_df.drop(columns=to_drop_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T20:52:56.959631Z",
     "iopub.status.busy": "2025-08-18T20:52:56.959196Z",
     "iopub.status.idle": "2025-08-18T20:52:57.068161Z",
     "shell.execute_reply": "2025-08-18T20:52:57.067030Z",
     "shell.execute_reply.started": "2025-08-18T20:52:56.959597Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Remove redundant features\n",
    "dl_reduced = dl_df.drop(columns=to_drop_dl)\n",
    "\n",
    "# Define map_to_binary function\n",
    "def map_to_binary(label):\n",
    "    return 1 if label == 'mel' else 0\n",
    "\n",
    "# Load labels for LDA\n",
    "metadata_df_indexed = pd.read_csv(metadata_path, index_col='image_id')\n",
    "labels = metadata_df_indexed.loc[common_ids, 'dx']  # Use original 'dx' (string labels)\n",
    "le = LabelEncoder()  # Encode strings to ints for LDA\n",
    "labels_encoded = le.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T20:53:01.661015Z",
     "iopub.status.busy": "2025-08-18T20:53:01.660540Z",
     "iopub.status.idle": "2025-08-18T20:53:16.044253Z",
     "shell.execute_reply": "2025-08-18T20:53:16.042616Z",
     "shell.execute_reply.started": "2025-08-18T20:53:01.660977Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA reduced features (6 components) saved to '/kaggle/working/resnet50_finetuned_lda_6.csv'\n"
     ]
    }
   ],
   "source": [
    "# Apply LDA for reduction to maximum possible components\n",
    "# Calculate the maximum number of components\n",
    "n_components = len(np.unique(labels_encoded)) - 1\n",
    "if n_components > 0:\n",
    "    # Convert all column names to strings to avoid TypeError\n",
    "    dl_reduced.columns = dl_reduced.columns.astype(str)\n",
    "    \n",
    "    lda = LinearDiscriminantAnalysis(n_components=n_components)\n",
    "    lda_features = lda.fit_transform(dl_reduced, labels_encoded)  # Use labels_encoded for numerical labels\n",
    "    lda_df = pd.DataFrame(lda_features, index=common_ids, columns=[f'lda_{i}' for i in range(n_components)])\n",
    "    lda_df.to_csv(f'/kaggle/working/resnet50_finetuned_lda_{n_components}.csv')\n",
    "    print(f\"LDA reduced features ({n_components} components) saved to '/kaggle/working/resnet50_finetuned_lda_{n_components}.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 54339,
     "sourceId": 104884,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1370616,
     "sourceId": 2275763,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8003660,
     "sourceId": 12665346,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8003791,
     "sourceId": 12665557,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 430058,
     "modelInstanceId": 412277,
     "sourceId": 525668,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
